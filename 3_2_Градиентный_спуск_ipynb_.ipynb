{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Градиентный спуск\n",
        "\n",
        "В этом задании нам предстоит реализовать классический алгоритм градиентного спуска для обучения модели логистической регрессии.\n",
        "\n",
        "Алгоритм выполнения этого задания следующий:\n",
        "\n",
        "* На основе посчитанных в первом задании частных производных, напишем функцию подсчета градиента бинарной кросс-энтропии по параметрам модели\n",
        "\n",
        "* Напишем функцию обновления весов по посчитанным градиентам\n",
        "\n",
        "* Напишем функцию тренировки модели\n",
        "\n",
        "Замечание:\n",
        "Тренировка модели проводится в несколько циклов, в рамках каждого из которых мы обновим веса модели, основываясь на предсказании для **каждого** объекта из датасета. Такие циклы называются *эпохами*. То есть одна эпоха - это набор обновлений весов, реализованный согласно посчитанным для каждого объекта из датасета ошибкам модели.\n",
        "\n",
        "Вам необходимо реализовать обучение модели в несколько эпох. Их количество задается параметром функции. В рамках каждой эпохи необходимо пройти циклом по всем объектам обучающей выборки и обновить веса модели."
      ],
      "metadata": {
        "id": "zVKa9zcWdm-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаблон кода для заполнения:"
      ],
      "metadata": {
        "id": "zrTqdyBid_G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "# Функция подсчета градиента\n",
        "def gradient(y_true: int, y_pred: float, x: np.array) -> np.array:\n",
        "    x = np.append(x, 1)\n",
        "    grad = (y_pred - y_true) * x\n",
        "    return grad\n",
        "\n",
        "# Функция обновления весов\n",
        "def update(alpha: np.array, gradient: np.array, lr: float):\n",
        "    alpha_new = alpha - lr * gradient\n",
        "    return alpha_new\n",
        "\n",
        "# функция тренировки модели\n",
        "def train(alpha0: np.array, x_train: np.array, y_train: np.array, lr: float, num_epoch: int):\n",
        "    alpha = alpha0.copy()\n",
        "    for epoch in range(num_epoch):\n",
        "        for i, x in enumerate(x_train):\n",
        "            y_true = y_train[i]\n",
        "            y_pred = 1 / (1 + np.exp(-np.dot(alpha, np.append(x, 1))))\n",
        "            grad = gradient(y_true, y_pred, x)\n",
        "            alpha = update(alpha, grad, lr)\n",
        "    return alpha"
      ],
      "metadata": {
        "id": "CCM4EIh_d8-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замечания:\n",
        "\n",
        "1. В случае, если у Вас возникли сложности с выполнением первого задания и, как следствие, у Вас не выходит сделать это, мы рекомендуем подробно ознакомиться с главой **Производные $\\frac{\\partial H}{\\partial \\omega_i}$** нашей [лекции](https://colab.research.google.com/drive/1xjX_YnXcRr8HSiYLByMHxEIAADqs7QES?usp=sharing).\n",
        "\n",
        "2. Обращайте внимание на названия и порядок аргументов в сдаваемых на проверку функциях - они должны совпадать с тем, что указано в шаблоне кода.\n",
        "\n",
        "3. Обратите внимание, что матрица объект-признак в описании параметров функций обозначает переменную типа numpy.array(), каждый элемент которой - объект типа numpy.array() - вектор признаков соответствующего объекта.\n",
        "\n",
        "4. Считайте, что свободный коэффициент a0 находится **в конце** списка alpha."
      ],
      "metadata": {
        "id": "zDcPxeLueFIk"
      }
    }
  ]
}