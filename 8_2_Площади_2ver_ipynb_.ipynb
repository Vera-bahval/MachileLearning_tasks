{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2. Площади\n",
        "\n",
        "В этой задаче Вам требуется сравнить значения метрик для 4 различных алгоритмов. Для этого отредактируйте следующий код так, чтобы он соответствовал сформулированному заданию."
      ],
      "metadata": {
        "id": "3gwOwJTzuYfl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjX6v8Y8uImZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ac1cfac9-9078-4a8b-a9ab-907db2747fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTODO: fit estimators and find best one\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve\n",
        "\"\"\"\n",
        "TODO: make additional imports here\n",
        "\"\"\"\n",
        "\n",
        "data = fetch_openml(data_id=42608)\n",
        "X, y = data['data'].drop(columns='Outcome').values, data['data']['Outcome'].astype(int).values\n",
        "\n",
        "X_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train)\n",
        "X_train, x_test = sc.transform(X_train), sc.transform(x_test)\n",
        "\n",
        "\"\"\"\n",
        "In the following part of code specify algorithms with their own parameters by yourself\n",
        "\"\"\"\n",
        "tree = DecisionTreeClassifier(random_state = 42)\n",
        "lr = LogisticRegression(random_state = 42)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "svm = SVC(probability=True, random_state = 42)\n",
        "\n",
        "tree.fit(X_train, y_train)\n",
        "tree_preds = tree.predict(x_test)\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "lr_preds = lr.predict(x_test)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "knn_preds = knn.predict(x_test)\n",
        "\n",
        "svm.fit(X_train, y_train)\n",
        "svm_preds = svm.predict(x_test)\n",
        "\n",
        "\"\"\"\n",
        "TODO: fit estimators and find best one\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "print(f\"1 roc_auc_score: {roc_auc_score(y_test, tree_preds)}\")\n",
        "print(f\"2 roc_auc_score: {roc_auc_score(y_test, lr_preds)}\")\n",
        "print(f\"3 roc_auc_score: {roc_auc_score(y_test, knn_preds)}\")\n",
        "print(f\"4 roc_auc_score: {roc_auc_score(y_test, svm_preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8BnHl2K-S_6",
        "outputId": "74f2fec1-e2b8-4101-987b-1d1b898053da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 roc_auc_score: 0.7043046357615894\n",
            "2 roc_auc_score: 0.7098509933774835\n",
            "3 roc_auc_score: 0.6627897350993378\n",
            "4 roc_auc_score: 0.7076572847682119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_scores = tree.predict_proba(x_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, tree_scores)\n",
        "tree_pr_auc = auc(recall, precision)\n",
        "print(f\"1 pr_auc: {tree_pr_auc}\")\n",
        "\n",
        "lr_scores = lr.predict_proba(x_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, lr_scores)\n",
        "lr_pr_auc = auc(recall, precision)\n",
        "print(f\"2 pr_auc: {lr_pr_auc}\")\n",
        "\n",
        "knn_scores = knn.predict_proba(x_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, knn_scores)\n",
        "knn_pr_auc = auc(recall, precision)\n",
        "print(f\"3 pr_auc: {knn_pr_auc}\")\n",
        "\n",
        "svm_scores = svm.predict_proba(x_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, svm_scores)\n",
        "svm_pr_auc = auc(recall, precision)\n",
        "print(f\"4 pr_auc: {svm_pr_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lptFa8758F-c",
        "outputId": "592ef9a7-f189-4548-dc49-a3e25134302e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 pr_auc: 0.6819480519480519\n",
            "2 pr_auc: 0.6635189014200681\n",
            "3 pr_auc: 0.5876288276242685\n",
            "4 pr_auc: 0.646433465148704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Примечания\n",
        "\n",
        "1. Обратите внимание, что StandardScaler может влиять на результаты работы алгоритмов. Поэтому рекомендуем его использовать.\n",
        "\n",
        "2. Когда мы разбиваем данные на train и test, мы должны понимать, что **все** алгоритмы должны обучаться **только на train**. Test при обучении **не используется**. Более того, в реальной жизни мы вообще ничего не знаем про test. Поэтому StandardScaler нужно обучать только на X_train, а к X_test делать только transform (**не** fit_transform)."
      ],
      "metadata": {
        "id": "PMPsE9S9N-nv"
      }
    }
  ]
}